---
layout: post
use_math: false
title: Converting Tables to RDF/OWL Ontologies (Draft)
tags: [snik, ontology, validation, property, domain, range]
date: 2017-01-13
---

# Problem
The SNIK ontology consists of the central meta ontology and several subontologies.
Each subontology is manually created by people reading text books and extracting their facts to spreadsheets, from now on called "tables".
As our final representation format is RDF/OWL, and there are thousands of rows extracted from each textbook, we need an automatic conversion method.
For our existing subontologies <sup name="a1">[1](#f1)</sup>





We used to have a special  

If we could choose the format of the tables freely, the task would be trivial, as we could define a mapping from CSV to RDF with a table containing one triple per row with three columns containing subject, predicate and object.
In that case we could also just let our extractors use RDF directly, but they are no RDF specialists

There is a tension between (1) the closeness to RDF/OWL and (2) the intuitiveness for the extractor.
(1) results in less mapping effort, more modelling freedom and less nunances lost in translation
while
(2) means less initial training, faster extraction and less modelling errors.
Further criteria for the tool we are looking for are (3) time for initial setup or development (4)

# Related Work

# SPARQLify CSV

As I had a few questions and wasn't sure which [branch or release](https://github.com/AKSW/Sparqlify) to check out, I met [Claus Stadler](http://aksw.org/ClausStadler.html), the developer of [SPARQLify](http://sparqlify.org/), a friend and colleague from AKSW.

As I don't have admin rights on my work computer, I installed it via `mvn clean install`, which took more than 12 minutes.
README says to do `mvn assembly:assembly` afterwards but that is broken right now, so we create the command ourselves (replace paths accordingly):

```
echo `java -cp /insert/path/to/sparqlify/sparqlify-cli/target/sparqlify-cli-0.8.0-jar-with-dependencies.jar org.aksw.sparqlify.csv.CsvMapperCliMain -h $@` > ~/bin/sparqlify
chmod +x ~/bin/sparqlify
```

The `-h` parameter says that our first row consists of table row headers for identification.

Now we can test it with:

```
sparqlify -c sparqlify-examples/src/main/resources/sparqlify-examples/csv/example1.sml -f sparqlify-examples/src/main/resources/sparqlify-examples/csv/example1.csv
```

If successfull, this generates some logging messages and ends with:

```
<http://example.org/hello> <http://example.org/name> "hello" .
<http://example.org/hello> <http://example.org/age> "world" .
<http://example.org/hello> <http://example.org/email> "bar" .
<http://example.org/hello> <http://example.org/isPositive> "true"^^<http://www.w3.org/2001/XMLSchema#boolean> .
<http://example.org/hello> <http://example.org/gender> "foo" .
Variable	#Unbound
Triples generated:	5
Potential triples omitted:	0
Triples total:	5
```

Now want to apply it to our own data and take look at the first few rows including the headers, where we removed spaces to use them in the [SML Mapping Language](http://sparqlify.org/smlLanguage):


| SubjektUri                     	| SubjDe                                  	| SubjEn                   	| SubjAltDe 	| SubjAltEn 	| Subjekttyp  	| Relation        	| Objekt               	| SeiteRelation 	| Definition                                        	| SeiteDefinition 	| Kapitel 	|
|--------------------------------	|-----------------------------------------	|--------------------------	|-----------	|-----------	|-------------	|-----------------	|----------------------	|---------------	|---------------------------------------------------	|-----------------	|---------	|
| Abgb                           	| Allgemeines Bürgerliches Gesetzbuch (Ö) 	|                          	| ABGB      	|           	| EntityType  	| rdfs:subClassOf 	| Gesetz               	|               	| Allgemeines Bürgerliches Gesetzbuch (Österreich). 	| Website;67      	| RECHT   	|
| Ablauforganisation             	| Ablauforganisation                      	| Organizational Structure 	|           	|           	| EntityType  	| meta:isBasedOn  	| ImKonzept            	| 18            	|                                                   	|                 	| ERMOD   	|
| AbleitenTeilstrategien         	| Ableiten von Teilstrategien             	|                          	|           	|           	| Function    	|                 	|                      	|               	|                                                   	| 117;120         	|         	|
| AbstimmenUnternehmensstrategie 	| Abstimmen mit der Unternehmensstrategie 	|                          	|           	|           	| Function    	| meta:uses       	| Wettbewerbsstrategie 	| 117           	|                                                   	|                 	|         	|
| AbstimmenUnternehmensstrategie 	| Abstimmen mit der Unternehmensstrategie 	| business-IT-alignment    	|           	|           	| Function    	|                 	|                      	|               	| Da die strategischen IT-Ziele [...]               	| 117             	|         	|
| Abstraktionsprinzip            	| Abstraktionsprinzip                     	|                          	|           	|           	| EntityType  	| rdfs:subClassOf 	| Architekturprinzip   	| 52            	| Das Abstraktionsprinzip verlangt [...]            	| 52              	| ARCHI   	|
| Abstraktionsprinzip            	| Abstraktionsprinzip                     	|                          	|           	|           	| EntityType  	| rdfs:subClassOf 	| Architekturprinzip   	| 52            	| Das Abstraktionsprinzip verlangt [...]            	| 52              	| ARCHI   	|

As SPARQlify cannot guess the prefixes of our entites, we had to provide them in the "Relation" column.
For SubjektUri, Subjekttyp, Relation and Objekt and Kapitel, we don't need prefixes though because they always imply the local (default) prefix, which we can add in the mapping.
It does not support already prefixed URIs and embraces them like `<rdfs:subClassOf>`.

The SML file that is surprisingly simple and needs only minor adaptions for future subontologies:

```
PREFIX owl: <http://www.w3.org/2002/07/owl#>
Prefix xsd: <http://www.w3.org/2001/XMLSchema#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX skos: <http://www.w3.org/2004/02/skos/core#>
PREFIX he: <http://www.snik.eu/ontology/he/>
PREFIX meta: <http://www.snik.eu/ontology/meta/>

Create View Template test As
  Construct {
    ?s  a owl:Class;
        meta:subTopClass ?st;
        rdfs:label ?lde, ?len;
        skos:altLabel ?lade, ?laden;
        ?p ?o;
        he:page ?pd;
        skos:definition ?d;
        he:chapter ?ch.
  }

With
    ?s = uri(he:, ?SubjektUri)
    ?st = uri(meta:, ?Subjekttyp)
    ?lde = plainLiteral(?SubjDe,"de")
    ?len = plainLiteral(?SubjEn,"en")
    ?lade = plainLiteral(?SubjAltDe,"de")
    ?laen = plainLiteral(?SubjAltEn,"en")
    ?p = uri(?Relation)
    ?o = uri(he:,?Objekt)
    ?pr = typedLiteral(?SeiteRelation,xsd:positiveInteger)
    ?d = plainLiteral(?Definition,"de")
    ?pd = typedLiteral(?SeiteDefinition,xsd:positiveInteger)
    ?ch = uri(he:,?Kapitel)
```

Also, it .





`sparqlify -c heinrich.sml -f htest.csv 2>&1  | grep -v TRACE`



<b name="f1">1</b> bb ()"blue book", "Health Information Systems") and ob ("orange book", IT-Projektmanagement im Gesundheitswesen) [↩](#a1)
