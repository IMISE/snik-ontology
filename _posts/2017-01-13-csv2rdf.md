---
layout: post
title: CSV2RDF: Converting Tables to RDF/OWL Ontologies
use_math: false 
tags: [snik, ontology, validation, property, domain, range]
---

# Problem
Our ontology is manually created by people reading text books and extracting their facts to spreadsheets (from now on: "tables"). As our final representation format is RDF/OWL, and there are thousands of rows extracted from each textbook, we need an automatic conversion method.
Because we think it is easiest to process tables in the plain text, comma separated value format CSV, we call this task "CSV2RDF".
If we could choose the format of the tables freely, the task would be trivial, as we could define a mapping from CSV to RDF with a table containing one triple per row with three columns containing subject, predicate and object.
In that case we could also just let our extractors use RDF directly, but they are no RDF specialists

There is a tension between (1) the closeness to RDF/OWL and (2) the intuitiveness for the extractor.
(1) results in less mapping effort, more modelling freedom and less nunances lost in translation
while
(2) means less initial training, faster extraction and less modelling errors. 
Further criteria for the tool we are looking for are (3) time for initial setup or development (4) 

# Related Work

# SPARQLify CSV

As I had a few questions and wasn't sure which [branch or release](https://github.com/AKSW/Sparqlify) to check out, I met [Claus Stadler](http://aksw.org/ClausStadler.html), the developer of [SPARQLify](http://sparqlify.org/), a friend and colleague from AKSW.

As I don't have admin rights on my work computer, I installed it via `mvn clean install`, which took more than 12 minutes.
README says do `mvn assembly:assembly` afterwards but that is broken right now, so we create the command ourselves (replace paths accordingly):

```
echo `java -cp /insert/path/to/sparqlify/sparqlify-cli/target/sparqlify-cli-0.8.0-jar-with-dependencies.jar org.aksw.sparqlify.csv.CsvMapperCliMain $@` > ~/bin/sparqlify
chmod +x ~/bin/sparqlify
```

Now we can test it with:

```
sparqlify -c sparqlify-examples/src/main/resources/sparqlify-examples/csv/example1.sml -f sparqlify-examples/src/main/resources/sparqlify-examples/csv/example1.csv -h
```

If successfull, this generates some logging messages and ends with:

```
<http://example.org/hello> <http://example.org/name> "hello" .
<http://example.org/hello> <http://example.org/age> "world" .
<http://example.org/hello> <http://example.org/email> "bar" .
<http://example.org/hello> <http://example.org/isPositive> "true"^^<http://www.w3.org/2001/XMLSchema#boolean> .
<http://example.org/hello> <http://example.org/gender> "foo" .
Variable	#Unbound
Triples generated:	5
Potential triples omitted:	0
Triples total:	5
```

[SML Mapping Language](http://sparqlify.org/smlLanguage)

`sparqlify -c heinrich.sml -f htest.csv 2>&1  | grep -v TRACE`



